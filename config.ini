[LLM]
endpoint = http://127.0.0.1:1234/v1/chat/completions
model_name = mathstral-7b-v0.1  # Corrected model name
temperature = 1
max_tokens = 4096